![](https://img.shields.io/badge/python-3.8-brightgreen.svg) ![](https://img.shields.io/badge/pytorch-1.10.0-orange.svg)

# A Deep Learning System for Predicting Size and Fit in Fashion E-Commerce

An (even more unofficial) PyTorch implementation of SizeFitNet (SFNet) architecture based on (unofficial) implementation of HareeshBahuleyan proposed in the paper [A Deep Learning System for Predicting Size and Fit in Fashion E-Commerce](https://arxiv.org/pdf/1907.09844.pdf) by Sheikh et. al (RecSys'19).

## Dataset
The original paper demonstrates experiments on two datasets:

1. ModCloth
2. RentTheRunWay

Both datasets are curated from fashion e-commerce websites that provide transaction information that contain `customer` attributes, `article` attributes and `fit` (target varible). `fit` is a categorical variable with `small`, `fit` and `large` as the possible labels. Only ModCloth dataset is going to be used.

## Model Architecture

The model consits of two pathways: one that captures user embeddings + user features, the other that captures item embeddings + item features. See the following figure taken from paper:

<br>
<img src="images/sfnet.png" width="500"/>
<br>

The representations within each pathway is transformed using skip connections. The authors compare it against an MLP (without skip connections) baseline and show better performance. 

Different from the paper, HareeshBahuleyan combines the user representation (u) and item representation (v) into a new tensor as below:
```
   [u, v, |u-v|, u*v]
```
- concatenation of the two representations
- element-wise product u âˆ— v
- absolute element-wise difference |u-v|

Based on: https://arxiv.org/pdf/1705.02364.pdf

This new representation is fed to the top layer skip connection block.

## Instructions

1. Start by installing the necessary packages (preferably within a Python virtual environment):
```
   pip install -r requirements.txt
```

2. Download the data from [here](https://www.kaggle.com/rmisra/clothing-fit-dataset-for-size-recommendation) and place it in the `data/` directory.

3. The original data is quite messy with quite a bit of missing values (NaNs). It is required to go through the `data_preparation.ipynb` notebook to create the working data. The notebook also provides instruction on creating the train/validation/test splits. 

4. Set data, model and training configurations by appropriately modifying the `jsonnet` files under `configs/` directory. If You don't know what hyperparameters to choose, let the script do it for You, just run the optune.py script using the following command:
```
   python optune.py
```
5. Train the SFNet Model:
```
   python train.py
```
The model checkpoints and run configuration will be saved under `runs/<experiment_name>`
The above also generates tensorboard plots of training loss and validation metrics, that would be useful to view training progress.

6. Test the Model:
```
   python test.py --model `runs/<experiment_name>`
```

## Acknowledgements
Thanks to Rishab Mishra for making the datasets used here publicly available on [Kaggle](https://www.kaggle.com/rmisra/clothing-fit-dataset-for-size-recommendation). The main skeleton structure and the training process of the model is highly inspired by [HareeshBahuleyan](https://github.com/HareeshBahuleyan/size-fit-net)

## Appendix
Significant parts are borrowed from Hareesh Bahuleyan, so I want to distinguish in this appendix,
which part of the code was written by me:
- the configs folder was fully written by Hareesh Bahuleyan
- the data folder contains the datasets and the data generated by augmentation
original data from Modcloth website, datasets
modcloth final data processed * were created from augmentation
by Hareesh Bahuleyan
- the images folder contains one image borrowed from a scientific article
by Abdul-Saboor Sheikh and other members of the team titled "A Deep Learning System for Predicting Size and Fit in Fashion E-Commerce": sfnet.png. The rest of the photos stayed created by the embeddings.py file
- the notebooks folder contains the data exploration.ipynb file by Hareesh
Bahuleyan, data preparation.ipynb that was modeled after
data exploration.ipynb, code created by me: 5 code cell, whole
Distribution Imputation, entire Calculationg Bust chapter, entire
the Calculating Waist chapter. The image table.png was borrowed from
the website https://shopsale.storesonline2022.ru/category?name=40%2090%20bra%20size%20conversion
- the runs folder keeps trained models ready for use. System
The recording of the models was created by Hareesh Bahuleyan
- The LICENCE file is a MIT license from the Hareesh Bahuleyan repository
- The README.MD file was largely written by Hareesh
Bahuleyan, I slightly edited the meaning by throwing up my opinion
unnecessary things by adding a mention of Hareesh Bahuleyan and adding
the optune.py manual
- the embeddings.py file was inspired by the training loop created by
Hareesh Bahuleyan. I have created: function
display pca scatterplot, code lines 131151
- modcloth.py was written by Hareesh Bahuleyan, mine is
addition of the code line 49
- model.py was written by Hareesh Bahuleyan
- the model tunes file was fully written by me
- the notebook file was fully written by me
- The optune.py file was inspired by the work of Hareesh Bahuleyan, mine
there are lines: 12, 1011, 22, 4073, 112, 118135, 175189
- the optune cv.py file was inspired by the works of Hareesh Bahuleyan,
mine are the lines: 12, 10, 21, 3057, 60-69, 159175
- the requirements.txt file was written by Hareesh Bahuleyan, I changed every single "==" character to ">=", 11 characters total
- test.py was fully written by Hareesh Bahuleyan, I added
modifications in the lines of the code: 4043, 47
- the train.py file was fully written by Hareesh Bahuleyan, added
by me the lines of the code: 7, 1920, 6978, 120, 123, 130144
- utils.py file was fully written by Hareesh Bahuleyan, added
by me lines of code: 4243
